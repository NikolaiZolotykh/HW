{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Нейронные сети.\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "Мы уверены, что выполнение лабораторных работ занимает значительное время, поэтому не рекомендуем оставлять их на последний вечер перед сдачей.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "* Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи)\n",
    "* Максимально допустимая оценка за всю работу — 15 баллов\n",
    "* Сдавать задание после указанного срока сдачи нельзя\n",
    "* «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса)\n",
    "* Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник)\n",
    "* Не оцениваются задания с удалёнными формулировкам\n",
    "* Не оценивается лабораторная работа целиком, если она была выложена в открытый источник\n",
    "\n",
    "Обратите внимание, что мы не ставим оценку за просто написанный код, корректная работоспособность которого не подтверждена экспериментами.\n",
    "\n",
    "### Правила сдачи\n",
    "Выполненную работу следует отправить в систему Anytask. Более подробно о системе можно почитать на странице курса. Название отправляемого файла должно иметь следующий формат: Surname_Name_Group_NN.ipynb, где NN — номер лабораторной работы. Например, Kozlova_Anna_CS_01.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Рекуррентные языковые модели\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSj85jp-W-V-Bz8ZBjFJYIkV1TTxQxTMh4iqls_rRt8O-sraL08PA)\n",
    "\n",
    "В этой части домашней работы мы создадим языковую модель на рекуррентных нейросетях (RNN) и заставим её придумывать имена.\n",
    "\n",
    "__Языковая модель__, если вкратце, это модель, которая умеет как предсказывать вероятность некоторого текста. Ее можно использовать также чтобы генерировать текст в соответствии с обученными вероятностями. Задание будет заключаться в том, чтобы научить модель генерировать новые имена, скормив ей для этого 8к существующих.\n",
    "\n",
    "В данном случае в качестве входных данных мы будет работать со строками, которые можно рассматривать как последовательности _символов_: $\\{x_0, x_1, x_2, ..., x_n\\}$. \n",
    "\n",
    "Наша основная задача — научиться предсказывать вероятность следующего символа:\n",
    "$$ p(x_0, x_1, x_2, ..., x_n) = \\prod_t p(x_t | x_0, ... x_{t - 1}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "\n",
    "Мы будем строить языковую модель по ~8k человеческих имён на латинице. Если когда-нибудь вам нужно будет дать имя своему ребёнку, у вас будет для этого генеративная нейросетевая модель.\n",
    "\n",
    "Давайте их прочитаем:\n",
    "* Считайте все строки из файла `./names` в список\n",
    "* В начало каждой строки допишите __пробел__\n",
    "* В конце сроки не должно быть переноса (`\\n`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "# YOUR CODE\n",
    "lines = [' ' + i.rstrip() for i in open('./names').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert all(line[0] == start_token for line in lines)\n",
    "assert all(line[-1] != '\\n' for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(lines))\n",
    "for x in lines[::1000]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте, что все корректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, lines))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "assert MAX_LENGTH == 16 , \"max length (for names) should be 16. remove assert if you work on different dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Словари\n",
    "\n",
    "В начале нам будет необходимо построить \"словарь\" — упорядоченное множество уникальных символов, которые сеть может породить. Это нужно, чтобы уметь сопоставить каждому символу свой номер. Перед отправкой в сеть все символы будут кодироваться их номерами в словаре.\n",
    "\n",
    "Также необходимо добавить в словарь пробельный символ, который будет использоваться в качестве специального токена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(list(''.join(lines))))#YOUR CODE\n",
    "\n",
    "tokens = sorted(list(tokens))\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь построим обратный словарь: для каждой буквы посчитаем её номер в списке токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {j: i for i, j in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И проверим, все ли корректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кажется заработало...\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"число токенов должно совпадать\"\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"словарь должен указывать на индекс буквы в tokens\"\n",
    "\n",
    "print(\"Кажется заработало...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея построенное соответствие, можно преобразовать батч входных данных в матрицу int32 номеров токенов. Так как в батче все строки должны быть одной длины, слишком короткие строки в батче нужно будет дополнить пробелами (паддинг)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(lines, max_len=None, pad=token_to_id[' '], dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.get, lines[i]))\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[ 0  3 30 29 35 29 33 40  0]\n",
      " [ 0  9 40 43 46 53  0  0  0]\n",
      " [ 0 18 46 37 47 47 37 33  0]\n",
      " [ 0  9 37 43 50 29 42 42 33]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(lines[::2000]))\n",
    "print(to_matrix(lines[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Один шаг RNN\n",
    "\n",
    "Рекуррентная нейронная сеть (RNN) — это такая сеть с <s>блокнотом</s> состоянием $h$, в который она умеет писать то, что видела.\n",
    "\n",
    "Сеть начинает с пустого $h_0 = \\vec 0$, после чего текст обрабатывается по одному символу:\n",
    "* $x_t$ — очередной символ, $h_t$ — предыдущее состояние\n",
    "* $h_{t+1} = \\text{get_h_next}(h_t, x_t)$ — новое состояние\n",
    "* $p(x_{t+1} | h_{t+1}) = \\text{get_probs}(h_{t+1})$ — вероятность следующего символа\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/8l4qFF0.png\" width=480>\n",
    "\n",
    "Поскольку $x_t$ это индекс символа в словаре (=натуральное число), то ему можно сопоставить некоторый обучаемый вектор (*embedding*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.1 (0.75 балла)**. Реализуйте вычисление нового состояния *get_h_next* и вероятности следующего символа *get_probs*, после чего напишите код для одного шага рекуррентной сети *rnn_one_step*, как на схеме выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras, keras.layers as L\n",
    "\n",
    "emb_size, rnn_size = 16, 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим слой, который сопоставляет каждому из n_tokens входов свой обучаемый вектор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_x = L.Embedding(n_tokens, emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь инициализируем слой, вычисляющий следующее состояния $[emb(x_t), h_t] \\to h_{t+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_h_next = L.Dense(rnn_size, activation=\"relu\") # YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, слой предсказывающий вероятности $h_{t+1} \\to P(x_{t+1}|h_{t+1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_probs = L.Dense(n_tokens, activation='softmax')# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации одного шага RNN реализуйте следующую последовательность действий:\n",
    "1. замените номер символа на его вектор (embedding) (*hint*: возможно, вам потребуется tf.reshape);\n",
    "2. сконкатенируйте вектор входа и предыдущее состояние;\n",
    "3. вычислите следующее состояние сети;\n",
    "4. предскажите вероятности для языковой модели P(x_next | h_next)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):  \n",
    "    \n",
    "    # YOUR CODE\n",
    "    print(tf.reshape(x_t,[-1,1]))\n",
    "    x_t_emb = embed_x(tf.reshape(x_t,[-1,1]))[:,0]\n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    output_probs = get_probs(h_next)\n",
    "    return h_next, output_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что все работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder('int32', (None, MAX_LENGTH))\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "# начальное состояние из нулей\n",
    "h0 = tf.zeros([batch_size, rnn_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "h1, p_y1 = rnn_one_step(input_sequence[:, 0], h0)\n",
    "\n",
    "dummy_data = np.arange(MAX_LENGTH * 2).reshape([2, -1])\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "test_h1, test_p_y1 = sess.run([h1, p_y1],  {input_sequence: dummy_data})\n",
    "\n",
    "assert test_h1.shape == (len(dummy_data), rnn_size)\n",
    "assert test_p_y1.shape == (len(dummy_data), n_tokens) and np.allclose(test_p_y1.sum(-1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Много шагов RNN\n",
    "\n",
    "После того как был реализован один шаг нейросети, самое время сделать этих шагов побольше. Самый простой способ это сделать — написать цикл для фиксированного числа шагов (`MAX_LENGTH`).\n",
    "\n",
    "**Задание 3.2 (0.25 балла)**. Реализуйте много шагов рекуррентной сети, на каждом шаге вычисляя следующее состояние RNN, исходя из предыдущего, при этом не забывая про *get_h_next* и *get_probs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_2:0\", shape=(?, 1), dtype=int32)\n",
      "Tensor(\"Reshape_4:0\", shape=(?, 1), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer dense_1: expected axis -1 of input shape to have value 80 but got shape (None, 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-eebc07def1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprobs_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# END OF YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ee9f4ad3ed81>\u001b[0m in \u001b[0;36mrnn_one_step\u001b[0;34m(x_t, h_t)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_t_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx_and_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_t_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mh_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_h_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_and_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moutput_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of input shape to have '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                                 \u001b[0;34m'value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                                 ' but got shape ' + str(x_shape))\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer dense_1: expected axis -1 of input shape to have value 80 but got shape (None, 71)"
     ]
    }
   ],
   "source": [
    "h_prev = h0\n",
    "predicted_probs = []\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]\n",
    "    # YOUR CODE\n",
    "    probs_next, h_next = rnn_one_step(x_t,h_prev)\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    predicted_probs.append(probs_next)\n",
    "    h_prev = h_next\n",
    "    \n",
    "predicted_probs = tf.stack(predicted_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-950b9d03c7ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpredicted_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "assert predicted_probs.shape.as_list() == [None, MAX_LENGTH, n_tokens]\n",
    "assert h_prev.shape.as_list() == h0.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение RNN\n",
    "\n",
    "Как и любую вероятностную модель, RNN можно обучить методом максимизации log-правдоподобия по всей выборке $D$:\n",
    "\n",
    "$$ \\theta = \\underset \\theta {argmax} \\log P(D) $$\n",
    "\n",
    "где\n",
    "$$ \\log P(D) = \\underset {\\vec x \\in D} \\sum \\log P(\\vec x) = \\underset {\\vec x \\in D} \\sum \\underset {x_t \\in \\vec x} \\sum \\log P(x_t | x_0, ..., x_{t+1})$$\n",
    "\n",
    "C тем же успехом мы можем __минимизировать__ кроссэнтропию — то же самое, но с минусом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-363f0c68264b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manswers_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions_matrix:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'answers_matrix:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "predictions_matrix = predicted_probs[:, :-1]\n",
    "answers_matrix = tf.one_hot(input_sequence[:, 1:], n_tokens)\n",
    "\n",
    "print('predictions_matrix:', predictions_matrix.shape)\n",
    "print('answers_matrix:', predictions_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.3 (0.5 балла)**. Реализуйте вычисление функции потерь (кроссэнтропия) и шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answers_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ec2117a20ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjectives\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answers_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "\n",
    "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))# YOUR CODE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss) # YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл обучения\n",
    "\n",
    "**Задание 3.4 (0.5 балла)**. Напишите цикл обучения:\n",
    "1. выбираем `batch_size` случайных строчек\n",
    "2. преобразуем их в матрицу индексов\n",
    "3. вычисляем функцию потерь и делаем шаг обучения\n",
    "4. записываем функцию потерь в `history`\n",
    "\n",
    "Для удобства отладки рекомендуем печатать или рисовать промежуточные результаты раз в несколько итераций.\n",
    "\n",
    "Также постарайтесь обойтись одним `sess.run` на итерацию цикла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "for i in range(1000):\n",
    "    # YOUR CODE HERE\n",
    "    batch = to_matrix(sample(names,32),max_len=MAX_LENGTH)\n",
    "    loss_i,_ = s.run([loss,optimize],{input_sequence:batch})\n",
    "    \n",
    "    \n",
    "    history.append(loss_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c6425f8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение RNN\n",
    "\n",
    "Только что у нас обучилась модель, которая предсказывает вероятности следующего символа.\n",
    "Теперь давайте применим её к строке из одного пробела. Получим вероятности первой буквы имени. После чего:\n",
    "* $x_t \\sim P(x_t | h_t)$ — выберем букву пропорционально вероятностям.\n",
    "* $h_{t+1} = \\text{get_h_next}(h_t, x_t)$ — присоединим букву к имени и прогоним через RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала инициализируем необходимые переменные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_6:0\", shape=(?, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_t = tf.placeholder('int32', (None,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_size], 'float32'))\n",
    "\n",
    "next_h, next_probs = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И будем использовать функцию ниже для генерации новых имен!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=' ', max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    sess.run(tf.variables_initializer([h_t]))\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         sess.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs, _ = sess.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что же придумала наша модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " KdPVZEECYgNBvHu\n",
      "  FhwEHAPQZLCNzJ\n",
      " U'VPPlohlDcLYpl\n",
      " aYGjxaKbS'tknLi\n",
      " TpTKSMjIKFLxaxJ\n",
      " aXFDy'DroSyGNeK\n",
      " xGogaJyRgINvGxF\n",
      " AghooahVQPPaxRt\n",
      " dKBlnFKWGqgarMH\n",
      " EpLIqpiRpBpEVsA\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumph'PUaLkTRK\n",
      " TrumpNOrIGIMfQ-\n",
      " TrumphEruNKCZPw\n",
      " TrumpdfGJztxSlV\n",
      " TrumpgCigQDpnDf\n",
      " TrumpIHpPKZKuVE\n",
      " TrumpMIauyLoQuj\n",
      " Trump'PhrNvBPnZ\n",
      " TrumpDUpXKJMh-X\n",
      " TrumpJYgTEPbgCS\n",
      " TrumpZrIHIYmHlT\n",
      " TrumpozHcZUWIxI\n",
      " TrumpqGNDUF pph\n",
      " TrumpkqFVTlhkzc\n",
      " TrumpNclGOYeqMt\n",
      " TrumpKTDHwqlKwr\n",
      " TrumpIGTqLU-CjS\n",
      " Trumpt-vYhJLRoX\n",
      " Trumpej'SebhauU\n",
      " TrumpFawdHuY-xn\n",
      " TrumpCoxDSVmnzA\n",
      " TrumpyKXLZbTo'F\n",
      " TrumpkFoDwKhdew\n",
      " TrumpXnMZuqaHkM\n",
      " TrumpZoBKTW Ehq\n",
      " TrumphYrWhKC'pl\n",
      " TrumpHdKCZcynti\n",
      " TrumpaLYxMDqykt\n",
      " TrumpiGOwylGXTy\n",
      " TrumpepLGucbfEX\n",
      " TrumpmRhHsDtTxw\n",
      " TrumpFwRn-RZtkS\n",
      " TrumpwxvMPkAGFG\n",
      " TrumprGAhQurWZr\n",
      " TrumpmL sSaJkin\n",
      " TrumpUuQlrxDUj \n",
      " TrumpSjirOmUX'S\n",
      " TrumpmmnOmgmKFw\n",
      " TrumpH-uamwgZjh\n",
      " TrumpVDb'BpkkQN\n",
      " TrumpWuVDR'y'rZ\n",
      " TrumpAd bv tRRg\n",
      " TrumpDNTcvqlRGu\n",
      " TrumpmlHZxUGhnm\n",
      " TrumpPzlUCeAgJ-\n",
      " TrumpMMupIoURZM\n",
      " TrumpOjQcprVGWS\n",
      " TrumpfoLoopaGIa\n",
      " TrumpNBxxWpSmNY\n",
      " TrumpTR-wXOPZL \n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что теперь?\n",
    "\n",
    "Если вам наскучит решать повседневные задачи или вам нужны новые идеи, вы теперь всегда можете воспользоваться RNN чтобы сгенерировать что-то новое. Вот несколько задач, от которых можно отталкиваться:\n",
    "* названия статей по глубинному обучению;\n",
    "* названия карт Magic The Gathering;\n",
    "* [имена покемонов](https://github.com/cervoise/pentest-scripts/blob/master/password-cracking/wordlists/pokemon-list-en.txt);\n",
    "* clickbait заголовки;\n",
    "* молекулы в формате [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system);\n",
    "* ваша фантазия, с ограничениями которой вы уже должны были понять как бороться.\n",
    "\n",
    "Если возьмётесь за эту задачу, то вот несколько полезных советов:\n",
    "* Сейчас модель обучается на коротких строчках. Если у вас роман, его придётся порезать на кускочки.\n",
    "* Если длина строк сильно варьируется, можно поставить параметр MAX_LENGTH так, чтобы он покрывал 90%. Это обычно дает ускорение примерно в 2 раза.\n",
    "* Для более сложных задач требуется больше нейронов (rnn_size). Кроме того, можно экспериментировать и со составляющими сети (см. ниже).\n",
    "\n",
    "### Ещё почитать\n",
    "\n",
    "* [Подборка советов](https://danijar.com/tips-for-training-recurrent-neural-networks/) по обучению RNN. Чуть более полезная, чем обычно.\n",
    "* Отличный блог-пост от Andrej Karpathy про языковые модели на rnn, их применение и визуализацию — [Unreasonable Effectiveness of RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n",
    "* Большой список статей, постов, реализаций и прочих полезностей по RNN - [awesome rnn](https://github.com/kjw0612/awesome-rnn).\n",
    "* [Зоопарк](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) готовых рекуррентных ячеек (LSTM, GRU) в TF. И ещё одна реализация [в карасе](https://keras.io/layers/recurrent/).\n",
    "* Сейчас мы настраиваем количество итераций заранее. Если вы хотите определять их динамически, милости просим в [tf.while_loop](https://www.tensorflow.org/api_docs/python/tf/while_loop) или [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan).\n",
    "* А ещё рекуррентные сети можно аугментировать механизмом внимания или долговременной памятью. Вот тут есть [хорошая статья](https://distill.pub/2016/augmented-rnns/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
